{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pep1cZYzqeBB",
    "outputId": "bdb77540-cb26-40fd-e09b-041a05d99a98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/davidporathur/anaconda3/lib/python3.12/site-packages (2.21.0)\n",
      "Requirement already satisfied: onnx in /home/davidporathur/anaconda3/lib/python3.12/site-packages (1.16.2)\n",
      "Requirement already satisfied: tf2onnx in /home/davidporathur/anaconda3/lib/python3.12/site-packages (1.16.1)\n",
      "Requirement already satisfied: filelock in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (0.24.6)\n",
      "Requirement already satisfied: packaging in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: six in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from tf2onnx) (24.3.25)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: accelerate in /home/davidporathur/anaconda3/lib/python3.12/site-packages (0.34.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from accelerate) (2.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from accelerate) (0.24.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (69.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/davidporathur/anaconda3/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers torch\n",
    "!pip install datasets onnx tf2onnx\n",
    "# !pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN='API_TOKEN'\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "import glob\n",
    "import numpy as np\n",
    "#import onnx\n",
    "#import tf2onnx\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidporathur/anaconda3/envs/sih/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-07 17:20:04.973294: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/davidporathur/anaconda3/envs/sih/lib/python3.8/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1926' max='1926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1926/1926 20:52, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.168400</td>\n",
       "      <td>0.113344</td>\n",
       "      <td>0.957425</td>\n",
       "      <td>0.958481</td>\n",
       "      <td>0.946500</td>\n",
       "      <td>0.970769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>0.961319</td>\n",
       "      <td>0.962402</td>\n",
       "      <td>0.947342</td>\n",
       "      <td>0.977949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the compute_metrics function\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='binary')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}  # Remove batch dimension\n",
    "        inputs['labels'] = torch.tensor(label)\n",
    "        return inputs\n",
    "\n",
    "# Load the datasets from multiple CSV files\n",
    "file_paths = glob.glob('datacsv/*.csv')  # Adjust the path pattern as needed\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', use_fast=True, clean_up_tokenization_spaces=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model part by part\n",
    "for file_path in file_paths:\n",
    "    # Load data for the current file\n",
    "    df = pd.read_csv(file_path)\n",
    "    texts = df['Description'].tolist()\n",
    "    labels = df['Label'].tolist()\n",
    "\n",
    "    # Split data into training and evaluation sets\n",
    "    train_texts, eval_texts, train_labels, eval_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "    eval_dataset = CustomDataset(eval_texts, eval_labels, tokenizer)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, pin_memory=True)  # Reduced batch size\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=32, shuffle=False, pin_memory=True)  # Reduced batch size\n",
    "\n",
    "    # Free up unused GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Move model to GPU\n",
    "    model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "    model.to('cuda')\n",
    "\n",
    "    # Define the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          # output directory\n",
    "        num_train_epochs=2,              # total number of training epochs per chunk\n",
    "        per_device_train_batch_size=8,   # Reduced batch size for training\n",
    "        per_device_eval_batch_size=32,   # Reduced batch size for evaluation\n",
    "        gradient_accumulation_steps=2,   # Accumulate gradients over 2 steps\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=10,\n",
    "        eval_strategy=\"epoch\",           # Updated parameter\n",
    "        fp16=True                        # Enable mixed precision training\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,       # Provide evaluation dataset\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()\n",
    "    #export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0_HAk3xqT_g",
    "outputId": "8767524b-6a75-4bf5-88df-91852cc3aa32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4054/2981125157.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('model.pth')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "# Save the trained model's state dictionary\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Optional: Convert to HDF5\n",
    "import h5py\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load('model.pth')\n",
    "\n",
    "# Save the state dictionary to an HDF5 file\n",
    "with h5py.File('model.h5', 'w') as f:\n",
    "    for key, value in state_dict.items():\n",
    "        f.create_dataset(key, data=value.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sih",
   "language": "python",
   "name": "sih"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
